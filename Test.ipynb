{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.wavenet import WaveNet\n",
    "from model.conv_encoder import ConvEncoder, ConvDecoder\n",
    "from model.vq_vae import VQ_VAE\n",
    "\n",
    "from vq_vae_trainer import VQ_VAE_Trainer\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Convolutional-Encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16000, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 8000, 32)          160       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 4000, 32)          4128      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2000, 32)          4128      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1000, 32)          4128      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 500, 32)           4128      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 250, 32)           4128      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 250, 1)            33        \n",
      "=================================================================\n",
      "Total params: 20,833\n",
      "Trainable params: 20,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"WaveNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 16000, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Initial-Causal-Convolution (Con (None, 16000, 32)    1056        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Layer0-Conv-Filter (Conv1D)     (None, 16000, 32)    4128        Initial-Causal-Convolution[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Layer0-Conv-Gate (Conv1D)       (None, 16000, 32)    4128        Initial-Causal-Convolution[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16000, 32)    0           Layer0-Conv-Filter[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16000, 32)    0           Layer0-Conv-Gate[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 16000, 32)    0           activation[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer0-Conv-Residual (Conv1D)   (None, 16000, 32)    1056        multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 16000, 32)    0           Initial-Causal-Convolution[0][0] \n",
      "                                                                 Layer0-Conv-Residual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer1-Conv-Filter (Conv1D)     (None, 16000, 32)    4128        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "Layer1-Conv-Gate (Conv1D)       (None, 16000, 32)    4128        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16000, 32)    0           Layer1-Conv-Filter[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16000, 32)    0           Layer1-Conv-Gate[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 16000, 32)    0           activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer1-Conv-Residual (Conv1D)   (None, 16000, 32)    1056        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16000, 32)    0           add[0][0]                        \n",
      "                                                                 Layer1-Conv-Residual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer2-Conv-Filter (Conv1D)     (None, 16000, 32)    4128        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Layer2-Conv-Gate (Conv1D)       (None, 16000, 32)    4128        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16000, 32)    0           Layer2-Conv-Filter[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16000, 32)    0           Layer2-Conv-Gate[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 16000, 32)    0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer2-Conv-Residual (Conv1D)   (None, 16000, 32)    1056        multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16000, 32)    0           add_1[0][0]                      \n",
      "                                                                 Layer2-Conv-Residual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer3-Conv-Filter (Conv1D)     (None, 16000, 32)    4128        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Layer3-Conv-Gate (Conv1D)       (None, 16000, 32)    4128        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16000, 32)    0           Layer3-Conv-Filter[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16000, 32)    0           Layer3-Conv-Gate[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 16000, 32)    0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer3-Conv-Residual (Conv1D)   (None, 16000, 32)    1056        multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16000, 32)    0           add_2[0][0]                      \n",
      "                                                                 Layer3-Conv-Residual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer4-Conv-Filter (Conv1D)     (None, 16000, 32)    4128        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Layer4-Conv-Gate (Conv1D)       (None, 16000, 32)    4128        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16000, 32)    0           Layer4-Conv-Filter[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16000, 32)    0           Layer4-Conv-Gate[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 16000, 32)    0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer4-Conv-Residual (Conv1D)   (None, 16000, 32)    1056        multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16000, 32)    0           add_3[0][0]                      \n",
      "                                                                 Layer4-Conv-Residual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer5-Conv-Filter (Conv1D)     (None, 16000, 32)    4128        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Layer5-Conv-Gate (Conv1D)       (None, 16000, 32)    4128        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16000, 32)    0           Layer5-Conv-Filter[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16000, 32)    0           Layer5-Conv-Gate[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 16000, 32)    0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer5-Conv-Residual (Conv1D)   (None, 16000, 32)    1056        multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16000, 32)    0           add_4[0][0]                      \n",
      "                                                                 Layer5-Conv-Residual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer6-Conv-Filter (Conv1D)     (None, 16000, 32)    4128        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Layer6-Conv-Gate (Conv1D)       (None, 16000, 32)    4128        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16000, 32)    0           Layer6-Conv-Filter[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16000, 32)    0           Layer6-Conv-Gate[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 16000, 32)    0           activation_12[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer6-Conv-Residual (Conv1D)   (None, 16000, 32)    1056        multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16000, 32)    0           add_5[0][0]                      \n",
      "                                                                 Layer6-Conv-Residual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer7-Conv-Filter (Conv1D)     (None, 16000, 32)    4128        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Layer7-Conv-Gate (Conv1D)       (None, 16000, 32)    4128        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16000, 32)    0           Layer7-Conv-Filter[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16000, 32)    0           Layer7-Conv-Gate[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 16000, 32)    0           activation_14[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer7-Conv-Residual (Conv1D)   (None, 16000, 32)    1056        multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16000, 32)    0           add_6[0][0]                      \n",
      "                                                                 Layer7-Conv-Residual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer8-Conv-Filter (Conv1D)     (None, 16000, 32)    4128        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Layer8-Conv-Gate (Conv1D)       (None, 16000, 32)    4128        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16000, 32)    0           Layer8-Conv-Filter[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16000, 32)    0           Layer8-Conv-Gate[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 16000, 32)    0           activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer8-Conv-Residual (Conv1D)   (None, 16000, 32)    1056        multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16000, 32)    0           add_7[0][0]                      \n",
      "                                                                 Layer8-Conv-Residual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Layer9-Conv-Filter (Conv1D)     (None, 16000, 32)    4128        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Layer9-Conv-Gate (Conv1D)       (None, 16000, 32)    4128        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16000, 32)    0           Layer9-Conv-Filter[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16000, 32)    0           Layer9-Conv-Gate[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 16000, 32)    0           activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Layer9-Conv-Residual (Conv1D)   (None, 16000, 32)    1056        multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16000, 32)    0           Layer0-Conv-Residual[0][0]       \n",
      "                                                                 Layer1-Conv-Residual[0][0]       \n",
      "                                                                 Layer2-Conv-Residual[0][0]       \n",
      "                                                                 Layer3-Conv-Residual[0][0]       \n",
      "                                                                 Layer4-Conv-Residual[0][0]       \n",
      "                                                                 Layer5-Conv-Residual[0][0]       \n",
      "                                                                 Layer6-Conv-Residual[0][0]       \n",
      "                                                                 Layer7-Conv-Residual[0][0]       \n",
      "                                                                 Layer8-Conv-Residual[0][0]       \n",
      "                                                                 Layer9-Conv-Residual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16000, 32)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv-Skip-Channels (Conv1D)     (None, 16000, 512)   16896       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16000, 512)   0           Conv-Skip-Channels[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16000, 512)   0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Final-Conv-Layer (Conv1D)       (None, 16000, 1)     513         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 111,585\n",
      "Trainable params: 111,585\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"Convolutional-Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, None, 32)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose (Conv1DTran (None, None, 32)          4128      \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTr (None, None, 32)          4128      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTr (None, None, 32)          4128      \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_3 (Conv1DTr (None, None, 32)          4128      \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_4 (Conv1DTr (None, None, 32)          4128      \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_5 (Conv1DTr (None, None, 32)          4128      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, None, 1)           33        \n",
      "=================================================================\n",
      "Total params: 24,801\n",
      "Trainable params: 24,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (sample_from_codebook), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'vector_quantizer/Codebook:0' shape=(64, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 16000, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_encoder (ConvEncoder)      (None, 250, 1)       20833       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pre-vq-conv (Conv1D)            (None, 250, 32)      64          conv_encoder[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "vector_quantizer (VectorQuantiz (None, 250)          2048        pre-vq-conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sample_from_codebook (Lambda)   (None, 250, 32)      0           vector_quantizer[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "straight_through_estimator (Lam (None, 250, 32)      0           sample_from_codebook[0][0]       \n",
      "                                                                 pre-vq-conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_decoder (ConvDecoder)      (None, 16000, 1)     24801       straight_through_estimator[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "wave_net (WaveNet)              (None, 16000, 1)     111585      conv_decoder[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 159,331\n",
      "Trainable params: 159,331\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# Current VQ-VAE implementation here\n",
    "# - Input audio\n",
    "# ---> Conv Encoder (Downsample)\n",
    "# ---> VQ (Latent space)\n",
    "# ---> Conv Decoder (Upsample)\n",
    "# ---> WaveNet (Generate)\n",
    "# - Output audio\n",
    "############################################################\n",
    "#wavenet = WaveNet()\n",
    "#conv_encoder = ConvEncoder()\n",
    "vq = VQ_VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44100, array([6, 5, 4, ..., 0, 0, 0], dtype=int16))\n"
     ]
    }
   ],
   "source": [
    "from scipy.io.wavfile import read\n",
    "import os\n",
    "DATA_PATH = r\"/home/rithomas/data/IDMT-SMT-GUITAR_V2/dataset1/Fender_Strat_Clean_Neck_SC/audio\"\n",
    "p = os.path.join(DATA_PATH, 'G53-40100-1111-00001.wav')\n",
    "print(read(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: <unknown>, types: tf.int32>\n",
      "tf.Tensor(\n",
      "[[[    2]\n",
      "  [    2]\n",
      "  [    4]\n",
      "  ...\n",
      "  [-1927]\n",
      "  [-1805]\n",
      "  [-1610]]\n",
      "\n",
      " [[  -48]\n",
      "  [  -45]\n",
      "  [  -41]\n",
      "  ...\n",
      "  [-1647]\n",
      "  [-2072]\n",
      "  [-2477]]\n",
      "\n",
      " [[   -4]\n",
      "  [   -5]\n",
      "  [   -5]\n",
      "  ...\n",
      "  [ -563]\n",
      "  [ -353]\n",
      "  [ -132]]\n",
      "\n",
      " [[    6]\n",
      "  [    5]\n",
      "  [    4]\n",
      "  ...\n",
      "  [ -201]\n",
      "  [ -197]\n",
      "  [ -187]]], shape=(4, 16000, 1), dtype=int32)\n",
      "Initializing from scratch.\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    2 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(2, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    2 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(2, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['vector_quantizer/Codebook:0'] when minimizing the loss.\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]\n",
      "\n",
      " [[nan]\n",
      "  [nan]\n",
      "  [nan]\n",
      "  ...\n",
      "  [nan]\n",
      "  [nan]\n",
      "  [nan]]], shape=(4, 16000, 1), dtype=float32)\n",
      "tf.Tensor([    4 16000     1], shape=(3,), dtype=int32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d318f3f5c54a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m }\n\u001b[1;32m     24\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVQ_VAE_Trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_CONFIGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/SingingVoiceConversion/vq_vae_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu_law_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/SingingVoiceConversion/vq_vae_trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1895\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m             \u001b[0msub_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1897\u001b[0;31m             extra_variables=self._trainable_weights))\n\u001b[0m\u001b[1;32m   1898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mgather_trainable_weights\u001b[0;34m(trainable, sub_layers, extra_variables)\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m   trainable_extra_variables = [\n\u001b[1;32m    273\u001b[0m       v for v in extra_variables if v.trainable]\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1895\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m             \u001b[0msub_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1897\u001b[0;31m             extra_variables=self._trainable_weights))\n\u001b[0m\u001b[1;32m   1898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mgather_trainable_weights\u001b[0;34m(trainable, sub_layers, extra_variables)\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m   trainable_extra_variables = [\n\u001b[1;32m    273\u001b[0m       v for v in extra_variables if v.trainable]\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1895\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m             \u001b[0msub_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1897\u001b[0;31m             extra_variables=self._trainable_weights))\n\u001b[0m\u001b[1;32m   1898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mgather_trainable_weights\u001b[0;34m(trainable, sub_layers, extra_variables)\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m   trainable_extra_variables = [\n\u001b[1;32m    273\u001b[0m       v for v in extra_variables if v.trainable]\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1895\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m             \u001b[0msub_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1897\u001b[0;31m             extra_variables=self._trainable_weights))\n\u001b[0m\u001b[1;32m   1898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mgather_trainable_weights\u001b[0;34m(trainable, sub_layers, extra_variables)\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m   trainable_extra_variables = [\n\u001b[1;32m    273\u001b[0m       v for v in extra_variables if v.trainable]\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m       \u001b[0mchildren_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_children_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainable_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchildren_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_dedup_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseen_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentitySet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2962\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2963\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m         \u001b[0;31m# Track the Variable's identity to avoid __eq__ issues.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/object_identity.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/object_identity.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Wrapper id() is also fine for weakrefs. In fact, we rely on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# id(weakref.ref(a)) == id(weakref.ref(a)) and weakref.ref(a) is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "## Dummy dataset to test architecture\n",
    "def generator():\n",
    "    for path in os.listdir(DATA_PATH):\n",
    "        if path.endswith('.wav'):\n",
    "            yield tf.expand_dims(read(os.path.join(DATA_PATH, path))[1][:16000]\n",
    "    \n",
    "ds = tf.data.Dataset.from_generator(generator, output_types=tf.int32)\n",
    "ds = ds.batch(4)\n",
    "print(ds)\n",
    "    \n",
    "DEFAULT_CONFIGS = {\n",
    "    'model_path': '/home/rithomas/cache/test_model',\n",
    "    'learning_rate': 0.0001,\n",
    "    'num_epochs': 100,\n",
    "    'print_every': 100\n",
    "}\n",
    "trainer = VQ_VAE_Trainer(vq, DEFAULT_CONFIGS)\n",
    "trainer.train(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
